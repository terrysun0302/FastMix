---
title: "FastMix User Guide"
author: "Hao Sun, Xing Qiu"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{FastMix User Guide}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r load-package, echo=FALSE, include=FALSE, message=FALSE}
library(knitr)
library(rmarkdown)
library(FastMix)
```


In this Vignette, we describe the basic usage of the `FastMix` package. This package implements a fast parameter estimation and hypothesis testing framework for a special type of linear mixed effects model inspired by the deconvolution project.  Below we describe the inspiring problem, the mathematical model, and the usage of the main R function, `FastMix()`. 

## Introduction

We will briefly describe a motivating problem for which the `FastMix` package is applicable.

In most genomic studies, gene expressions are quantified from a mixture of heterogeneous cells.  In certain cases, we may have matching phenotype data (often from flow-cytometry) which quantify the proportion of $k=1, 2, \dots, K$ types of cells in the sample. One popular task is to use the observed cell proportions to "deconvolute" the mixed gene expressions, namely, to obtain cell-specific gene expressions for each subject (henceforth denoted as $b_{kij}$, for the $k$th cell, $i$th gene, $j$th subject). 

In a sense, the need for producing *subject-specific* expressions is primarily driven by the downstream statistical analysis, in which $b_{kij}$ are considered as new observations to be associated with subject-specific clinical covariates, such as the disease severity, age, and sex.

From the statistical perspective, the main difficulty of the above approach is that the deconvolution step is a typical "large $p$, small $n$" problem.  For each gene, we have $n$ observations of the mixed gene expression; yet our goal is to produce $Kn$ estimates for each subject ($i=1, 2, \dots, n$) and each type of cell ($k=1, 2, \dots, K$).  While it is theoretically doable based on certain penalized regression, the resulting cell-specific expressions will inevitably have high level of variance.

In this study, we take a different approach, namely, to combine the deconvolution step with the downstream analysis into a **single** mixed effects model.  The advantages of doing so are:

1. Cell-specific gene expressions are modeled as a mixture of fixed and random effects, so each subject (and each cell, each gene) can have a different estimate $\hat{b}_{kij}$ via EBLUP (empirical best linear unbiased predictor).
2. The degrees of freedom (unknown parameters) of the above model is small. Specifically, subject-specific variation of $\hat{b}_{kij}$ is controlled by clinical covariates via a linear model.
2. The primary inference is based on the interaction between the cell proportions and clinical covariates, which pools all subjects, so there is no "small $n$, large $p$" problem. The results will be a set of $p$-values for each cell type and each clinical covariate.
3. We also developed a novel gene prioritizing procedure based on the theory of outliers.  More specifically, among all the predicted random effect terms (cell, covariate, and gene) for a fixed cell and covariate, we will be able to identify those genes that are significantly different from the majority of genes. The result will be a 3D tensor of $p$-values for cell, covariate, and gene, as well as the the direction and magnitude of this random interaction term being greater than the average.

In summary, we have designed a **one-step** inferential framework based on mixed effects regression and outlier analysis for the deconvolution analysis that greatly reduces the model complexity, yet still flexible enough to produce estimates of the association between the cell-specific gene expressions and clinical covariates, as well as their corresponding $p$-values for each gene, cell, and covariate.

## Mathematical model

Based on a simple additive model, $Y_{ji}$, the expression level of the $i$th gene, $i=1, 2, \dots, m$ for the $j$th subject, $j=1, 2, \dots, n$, can be described as 

$$Y_{ji} = \sum_{k=1}^{K} C_{jk} b_{kij} + \sum_{p=1}^{P} Z_{jp} d_{pi} + \epsilon_{ji}. $$

Here $C_{jk}$ is the proportion of the $k$th cell for the $j$th subject (measured by e.g., flow-cytometry); $b_{kij}$ is the expression of the $i$th gene produced by one unit of $k$th cell for the $j$th subject; $Z_{jp}$ is the value of the $p$th **standardized** clinical variable (such as age, sex, and severity; standardized so that all of them have mean zero and unit standard deviation therefore directly comparable) of the $j$th subject; $d_{pi}$ is the association of the $p$th clinical covariate to the $i$th gene; and $\epsilon_{ji}$ is the error term.  We further assume that the cell-specific expression, $b_{kij}$, and covariate-specific association, $d_{pi}$, have the following mixed effects structure 

$$ b_{kij} = b_{k} + u_{ki} + \sum_{p=1}^{P} Z_{jp} (a_{pk} + \alpha_{pki}), \qquad d_{pi} = \delta_{p} + e_{pi}. $$

Here $b_{k}$ is the mean contribution to expression from the $k$th cell to all genes; $u_{ki}$ is a random effect term specific to the $i$th gene;  $a_{pk}$ represents the mean (over all subjects and genes) association between $Z_{jp}$ and $b_{kij}$; and $\alpha_{pki}$ is a random effect term that describes the association of $Z_{jp}$ and a specific gene; $\delta_{p}$ is the overall association of $p$ to all genes and $e_{pi}$ is a random effect that describes the association between the $p$th covariate and the $i$th gene.

We may merge the first two equations and obtain the following **combined model**

$$ Y_{ji} = \sum_{l = 1}^{L} X_{jl} \left( \beta_{l} + \gamma_{li} \right) + \epsilon_{ji}. $$

Here $X_{\cdot, \cdot}$ is the combined covariate matrix and it includes $C_{jk}$, $Z_{jp}$, and $C_{jk} Z_{jp}$. For example, if we have three types of cells and two clinical covariates, the total number of covariates would be $L = 3 + 2 + 3\times 2 = 11$. $\beta_{l}$ is the contribution of $X_{\cdot,l}$ (could be $C$, $Z$, or their interaction) to the entire transcriptome, and $\gamma_{li}$ is the random effect term that characterizes the effect of $X_{\cdot,l}$ to a specific gene.

## Computational challenge and the Fast LMER algorithm

The above model is a standard LMER so it can be fitted by a stock mixed effects regression software, such as R package `lme4`, the reference implementation of LMER in R.  However, due to the high-throughput nature of the data, fitting such a large regression model is computationally very demanding.  Furthermore, there are occasional convergence issues due to the use of the EM algorithm in `lme4` to the high-throughput data, which could do harm to the parameter estimation of interest. See the simulation studies in document `FAST_LMER_project.pdf`. 

Instead, we developed an efficient estimation framework based on an initial OLS regression, moment method, and the EBLUP. For high-throughput data, the proposed method achieves comparable accuracy with the EM-based LMER ﬁtting algorithm with only a fraction of computational time. 

## The outlier detection algorithm for the predicted random effects

In addition, we develop a novel competitive hypothesis test to identify genes that have signiﬁcantly larger or smaller predicted random eﬀect with a given
covariatewe. It means for a given $l$, whether the estimated random effect for a specific gene ($\gamma_{li}$) is significantly different from its "main distribution".  Specifically, we consider that the previous **combined model** only describes the distribution of the majority of genes; and there may be small subsets of genes that have different distribution of linear coefficients.  In other words, if gene $i$ is in this subset, its linear coefficient associated some $X_{\cdot l}$ does **not** follow $N(\beta_{l}, \sigma_{\gamma_{l}}^2)$, and could be detected as an **outlier** from the major distribution.  

The proposed outlier detection includes two steps: debias the covariance estimation of random effects caused by outliers and do z-test using weighted EBLUP . Step one is the core part and we briefly describe how to achieve it here: we first find the potential direction with outliers by a normal test of weighted EBLUP; we then construct a $\chi^2$-type statistics from OLS estimation and trim the extreme values to do gene selection; lastly we recover the covariance estimation of random effects according to the proporty of trimmed $\chi^2$-distribution. 
Technical details and simulation results are summarized in another document, `FAST_LMER_project.pdf`.

## Usage examples

The primary function in our package is `FastMix()`.  It takes the following primary arguments: `GeneExp`, `CellProp`, `Clinical`, `random` and `robust`. Here `GeneExp` is a $m\times n$ dimensional gene expression matrix; `CellProp` is a $n\times K$ dimensional matrix of cell proportions; `Clinical` is a $n\times P$ dimensional matrix of clinical and demographic variables to be tested; `random` is an index vector that specifies which variable(s) requires random effects -- by default, all covariates are paired with a random effect and `robust` specifies whether robust covariance estimation is implemented and which method to use:  "FALSE" for non-robust estimation; "mcd" for the MCD algorithm of Rousseeuw and Van Driessen; "weighted" for the Reweighted MCD; "donostah" for the Donoho-Stahel projection based estimator; "pairwiseQC" for the orthogonalized quadrant correlation pairwise estimator. All these algorithms come from the R package `robust`. "FastMix" is the proposed trimming method.  

## Simulation 

In this simulated study, there are $m=`r m`$ genes and $n=`r n`$ subjects. There are three cell types and the data are stored in object `CellProp`.  I created a clinical dataset called `Demo`, which consists of two variables, `Severity` and `Sex`.  Based on the previous discussion, the observed bulk gene expression may be associated with a total of $L=11$ covariates: 3 cell proportions, 2 clinical variables, and 6 of the interaction terms.  

I created true associations between the covariates and gene expressions in this way. 

1. Cell1 has overall association with all gene expressions; Cell 2 and 3 does not. Using previous notation, $b_1 = `r bb[1]`$, $b_2 = `r bb[2]`$, $b_3 = `r bb[3]`$.  
2. The majority of the genes are associated with these cells with coefficients sampled from $N(0, \sigma_{u}^{2})$, $\sigma_{u} = `r sigma2.u`$.
3. Neither Severity nor Sex has overall association with the entire transcriptome.  The majority of their coefficients follow $N(0, \sigma_{e}^{2})$, $\sigma_{e} = `r sigma2.e`$.
4. The interaction between Cell1 and Severity has an overall impact on the transcriptome; the corresponding coefficients follows $N(\beta_6, \sigma_{\alpha}^2)$, $\beta_6 = `r aa[1]`$, $\sigma_{\alpha} = `r sigma2.alpha`$. 
5. All other interaction terms do not have overall association with the transcriptome. The majority of these 11 coefficients has correlation 0.5. We then choose 4 out of 11 covariates to assign outliers. 
6. The first 250 genes have strong association with Cell1, such that $b_{1i} = b_{1} \pm 3 \times \sigma_{u}$, with equal probability of positive or negative shift. In other words, their linear coefficients are outliers w.r.t. the major distribution.
7. The linear coefficients between Genes 251 - 500 and Severity are outliers created in the same way ($\pm 3 \times \sigma_{e}$ units).
8. The linear coefficients between Genes 501 - 750 and Cell2.Severity, and those between Genes 751 - 1000 and Cell2.Sex are outliers created in the same way ($\pm 3 \times \sigma_{\alpha}$ units).
9. The variance of the noise, $\sigma_{\epsilon}^2$, is `r sigma2.err`.

### Structure of Simulated Data

We provide a data example called `dataexample.rda` to examplify the simulated data. Notice that three data input are needed for function `FastMix()`.The object `CellProp` stores the proportion of cell types for each subject with 50 rows and 3 columns. The object `Demo` is a clinical dataset which consists of two variables, `Severity` and `Sex`, for each subjects with 50 rows and 2 columns. The object `GeneExp`, a  matrix with 5000 rows and 50 columns, stores the outcome of interest which consists of gene expression level with respect to subjects and genes. Based on the previous discussion, the observed bulk gene expression may be associated with a total of $L=11$ covariates: 3 cell proportions, 2 clinical variables, and 6 of the interaction terms.  

### Using FastMix to analyze the simulated data

Below is the default way of using `FastMix` to analyze the simulated data

```{r run-Fastmix, include=TRUE, echo=TRUE}

library(FastMix)
data(dataexample)                       #loads the sample data
#vignette("FastMix")                     #shows this vignette

## fitting the gene expression data, cell proportions, and demographic
## data in one step. It takes about 10~15 seconds to finish computing
system.time(mod1 <- FastMix(GeneExp, CellProp, Demo, independent = F))

```

Now let us summarize the results. First, let us check the fixed effects (the overall association between the covariates, their interactions, and the transcriptome

```{r fixed-effects, include=TRUE, echo=TRUE, results='asis'}

## 1. The overall association between covariates (with interactions)
## and the entire transcriptome. We know that Cell1 is significantly
## associated with all genes; and Cell1 has a significant interaction
## with Severity (but not Sex). All other nine covariates are not
## significant.
kable(round(mod1$fixed.results, 4))

```

As we can see, FastMix correctly identified the only two truly significant covariates (Cell1 and the interaction between Cell1 and Severity).

Next, we check the statistical power and type I error rate for the
random effects. 


```{r random-effects, include=TRUE, echo=TRUE, results='asis'}

## (a) The first 250 genes have significant association with Cell1,
## (b) genes 251-500 has significant association with Severity, (c)
## genes 501 - 750 are significantly associated with Cell2.Severity,
## and (d) genes 751 - 1000 are significantly associated with Cell2.Sex.
m <- nrow(GeneExp)
rr.cell1 <- c(Power=sum(mod1$re.ind.pvalue[1:250, "Cell1"]<0.05)/250,
              TypeI.Err=sum(mod1$re.ind.pvalue[251:m, "Cell1"]<0.05)/(m-250))
rr.severity <- c(Power=sum(mod1$re.ind.pvalue[251:500, "Severity"]<0.05)/250,
                 TypeI.Err=sum(mod1$re.ind.pvalue[c(1:250, 501:m), "Severity"]<0.05)/(m-250))
rr.cell2.severity <- c(Power=sum(mod1$re.ind.pvalue[501:750, "Cell2.Severity"]<0.05)/250,
                 TypeI.Err=sum(mod1$re.ind.pvalue[c(1:500, 751:m), "Cell2.Severity"]<0.05)/(m-250))
rr.cell2.sex <- c(Power=sum(mod1$re.ind.pvalue[751:1000, "Cell2.Sex"]<0.05)/250,
                 TypeI.Err=sum(mod1$re.ind.pvalue[c(1:750, 1001:m), "Cell2.Sex"]<0.05)/(m-250))
rr.others <- c(Power=NA, TypeI.Err=sum(mod1$re.ind.pvalue[, -c(1,4,10)]<0.05)/(m*8))
retab <- cbind(Cell1=rr.cell1, Severity=rr.severity, Cell2.Severity=rr.cell2.severity,
               Cell2.Sex=rr.cell2.sex, Others=rr.others)

kable(round(retab, 3))

```

Judging from the above table, we see that for all covariates, the type I error is controlled at the nominal level. We also noticed that for all covariates, we have relatively good power to detect gene-specific associations between the covariates, including the interactions between cell proportion, clinical variables, and gene expressions.

### Extention to weighted samples.

In many applications, the noise may not be i.i.d, and the idea behind weighted least square (WLS) can be used to overcome this issue. One example is that, in the above simulation study, the $n = 50$ subjects are measured at 5 different locations, and the error terms have diffferent variance due to the location effect. We modify the simulation study as follows as an example:

1, All subjects are independent, but are not identically distributed. The variance of the noise for the first 25 subjects are $\sigma_{\epsilon}^2$; the variance of the noise for the subjects 26 to 50 are $2 \sigma_{\epsilon}^2$. 
2, This weight structure should be known. 

With this information (the noise structure), we can use weighted smaples in the piepline:

```{r weighted sample, include=TRUE, echo=TRUE, results='asis'}
weight_matrix = diag(c(rep(c(1,2), each = 25)))
### we generate a weighted data
dat = data_gen(m, n, seed = 10, outlier = T, cor = 0.5, balance = F, weight = weight_matrix)

set.seed(123)
system.time(mod2 <- FastMix(dat$GeneExp, dat$CellProp, dat$Demo, independent = F, weight_matrix = weight_matrix))

rr.cell1 <- c(Power=sum(mod2$re.ind.pvalue[1:250, "Cell1"]<0.05)/250,
              TypeI.Err=sum(mod2$re.ind.pvalue[251:m, "Cell1"]<0.05)/(m-250))
rr.severity <- c(Power=sum(mod2$re.ind.pvalue[251:500, "Severity"]<0.05)/250,
                 TypeI.Err=sum(mod2$re.ind.pvalue[c(1:250, 501:m), "Severity"]<0.05)/(m-250))
rr.cell2.severity <- c(Power=sum(mod2$re.ind.pvalue[501:750, "Cell2.Severity"]<0.05)/250,
                 TypeI.Err=sum(mod2$re.ind.pvalue[c(1:500, 751:m), "Cell2.Severity"]<0.05)/(m-250))
rr.cell2.sex <- c(Power=sum(mod2$re.ind.pvalue[751:1000, "Cell2.Sex"]<0.05)/250,
                 TypeI.Err=sum(mod2$re.ind.pvalue[c(1:750, 1001:m), "Cell2.Sex"]<0.05)/(m-250))
rr.others <- c(Power=NA, TypeI.Err=sum(mod2$re.ind.pvalue[, -c(1,4,10)]<0.05)/(m*8))
retab <- cbind(Cell1=rr.cell1, Severity=rr.severity, Cell2.Severity=rr.cell2.severity,
               Cell2.Sex=rr.cell2.sex, Others=rr.others)

kable(round(retab, 3))

set.seed(123)
system.time(mod3 <- FastMix(dat$GeneExp, dat$CellProp, dat$Demo, independent = F, weight_matrix = NULL))

rr.cell1 <- c(Power=sum(mod3$re.ind.pvalue[1:250, "Cell1"]<0.05)/250,
              TypeI.Err=sum(mod3$re.ind.pvalue[251:m, "Cell1"]<0.05)/(m-250))
rr.severity <- c(Power=sum(mod3$re.ind.pvalue[251:500, "Severity"]<0.05)/250,
                 TypeI.Err=sum(mod3$re.ind.pvalue[c(1:250, 501:m), "Severity"]<0.05)/(m-250))
rr.cell2.severity <- c(Power=sum(mod3$re.ind.pvalue[501:750, "Cell2.Severity"]<0.05)/250,
                 TypeI.Err=sum(mod3$re.ind.pvalue[c(1:500, 751:m), "Cell2.Severity"]<0.05)/(m-250))
rr.cell2.sex <- c(Power=sum(mod3$re.ind.pvalue[751:1000, "Cell2.Sex"]<0.05)/250,
                 TypeI.Err=sum(mod3$re.ind.pvalue[c(1:750, 1001:m), "Cell2.Sex"]<0.05)/(m-250))
rr.others <- c(Power=NA, TypeI.Err=sum(mod1$re.ind.pvalue[, -c(1,4,10)]<0.05)/(m*8))
retab <- cbind(Cell1=rr.cell1, Severity=rr.severity, Cell2.Severity=rr.cell2.severity,
               Cell2.Sex=rr.cell2.sex, Others=rr.others)

kable(round(retab, 3))
```

The first table shows the results using sample-specific weights while the second table shows the results without sample-specific weights. We see that for all covariates, the type I error is controlled at the nominal level when weights are used. The type I error without weights are pretty small. We also noticed that when weights are used, we have relatively better power to detect gene-specific associations between the covariates, including the interactions between cell proportion, clinical variables, and gene expressions. See the paper for more details. 

## Real data example

To be written later based on the UR/JCVI collaboration on the RPRC data.

